{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library/Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time, random\n",
    "import numpy as np    \n",
    "from scipy import signal as sig    # Signal Processing\n",
    "from scipy import interpolate    # Interpolation\n",
    "import matplotlib.pyplot as plt    # Plot Tool\n",
    "import matplotlib.mlab as mlab    # PSD Estimation\n",
    "\n",
    "import cupy as cp    # For GPU\n",
    "import chainer    # Neural Network Framework\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer.dataset import convert\n",
    "from chainer.datasets import TupleDataset\n",
    "from chainer import serializers\n",
    "\n",
    "from function.noise import *    # Noise Production\n",
    "from function.Ringdown_signal import *    # Ringdown Signal Production\n",
    "from function.matched_filter import *    # Matched Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can produce pseudo noise data by running 'noise.py' .  \n",
    "The source code is like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_format(data_name):\n",
    "    with open(data_name, 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    data = data.split('\\n')\n",
    "    del data[-1]\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data[i] = float(data[i])\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def rand_sample(data, fs, L):\n",
    "    # PSD Estimation\n",
    "    dt = 1.0 / fs\n",
    "    NFFT = fs\n",
    "    \n",
    "    psd, freqs = mlab.psd(data, Fs=fs, NFFT=NFFT)\n",
    "    \n",
    "    # Whitening\n",
    "    Nt = L\n",
    "    data2 = data\n",
    "    \n",
    "    hf = np.fft.rfft(data2)\n",
    "    white_hf = hf / np.sqrt(psd / dt / 2)\n",
    "    white_hf = np.fft.irfft(white_hf, Nt)\n",
    "    \n",
    "    # Randomization\n",
    "    rand_hf = np.random.permutation(white_hf)\n",
    "    rand_hf = np.fft.rfft(rand_hf)\n",
    "    rand_hf = rand_hf * np.sqrt(psd / dt / 2)\n",
    "    rand_hf = np.fft.irfft(rand_hf)\n",
    "    \n",
    "    norm_factor = np.median(np.abs(rand_hf)) / np.median(np.abs(data))\n",
    "    rand_hf = rand_hf / norm_factor\n",
    "    \n",
    "    return rand_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_format : Formating LIGO's raw data(.txt).  \n",
    "rand_sample : Permutation test function for formated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to set sampling frequency(fs) and data length(L).  \n",
    "Here, sampling frequency of LIGO's raw data is 4096Hz, so fs = 4096.\n",
    "And we use 1 second data for this time, so L = 4096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of data\n",
    "DATA_PATH = '../data/GW150914_4096Hz_1s.txt'\n",
    "\n",
    "# Parameters of data\n",
    "fs = 4096\n",
    "L = 4096\n",
    "\n",
    "# Loading and formating\n",
    "raw_data = data_format(DATA_PATH)\n",
    "\n",
    "# Permutation test\n",
    "noise = noise(raw_data, fs=fs, L=L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can get noise data(t-domain), and the size is (4096, )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ringdown Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get Ringdown Signal by running 'Ringdown_signal.py' .  \n",
    "The source code is like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ringdown_signal_generator(m1, m2, a, t, A22, theta, tau_index):\n",
    "    q = m2 / m1\n",
    "    if q < 1:\n",
    "        q = 1 / q\n",
    "        \n",
    "    nu = q / ((1 + q)**2)                         # Mass ratio\n",
    "    \n",
    "    m = round((m1 + m2) * 0.96, 1)     # Mass after the merger：4% of this mass is convert to GWs, so after mass is 96%.\n",
    "    a = round(a, 3)\n",
    "    \n",
    "    t[:tau_index] = 0\n",
    "    t[tau_index:] = t[tau_index:] - t[tau_index]      # Reshape of t\n",
    "\n",
    "    # QNM parameter\n",
    "    f, q = QNM_parameter(a, m)\n",
    "    \n",
    "    f_22 = f[0]\n",
    "    f_33 = f[1]\n",
    "    f_44 = f[2]\n",
    "    q_22 = q[0]\n",
    "    q_33 = q[1]\n",
    "    q_44 = q[2]\n",
    "    \n",
    "    # Amplitude of spherical harmonics\n",
    "    Y22 = plus_GW_spherical_harmonics(theta, 2, 2)\n",
    "    Y33 = plus_GW_spherical_harmonics(theta, 3, 3) / Y22\n",
    "    Y44 = plus_GW_spherical_harmonics(theta, 4, 4) / Y22\n",
    "    \n",
    "    # Amplitude\n",
    "    A33 = Y33 * A22 * 0.44 * (1- 4*nu)**0.45\n",
    "    A44 = Y44 * A22 *(5.4 * (nu - 0.22)**2 + 0.04)\n",
    "    \n",
    "    # Signal\n",
    "    \n",
    "    signal_22 = A22 * np.exp(-math.pi * f_22 / q_22 * t) * np.sin(2 * math.pi * f_22 * t)\n",
    "    signal_33 = A33 * np.exp(-math.pi * f_33 / q_33 * t) * np.sin(2 * math.pi * f_33 * t)\n",
    "    signal_44 = A44 * np.exp(-math.pi * f_44 / q_44 * t) * np.sin(2 * math.pi * f_44 * t)\n",
    "    signal = signal_22 + signal_33 + signal_44\n",
    "    \n",
    "    return np.real(signal)\n",
    "    \n",
    "def QNM_parameter(a,m):\n",
    "    f_sig = np.array([[1.5251, -1.1568, 0.1292], [1.8956, -1.3043, 0.1818], [2.3000, -1.5056, 0.2244]])     # 22, 33, 44 mode、row:mode, columun:index\n",
    "    q_sig = np.array([[0.7000, 1.4187, -0.4990], [0.9000, 2.3430, -0.4810], [1.1929, 3.1191, -0.4825]])\n",
    "    \n",
    "    f = np.zeros(3)\n",
    "    q = np.zeros(3)\n",
    "    \n",
    "    for i in range(len(f_sig)):\n",
    "        f[i] = 32 * (f_sig[i, 0] + f_sig[i, 1] * (1 - a)**f_sig[i, 2]) / m * 10**3\n",
    "        q[i] = q_sig[i, 0] + q_sig[i, 1] * (1 - a)**q_sig[i, 2]\n",
    "        \n",
    "    return f, q\n",
    "\n",
    "def plus_GW_spherical_harmonics(theta, l, m):       # theta:Inclination, l,m:QNM mode\n",
    "    s = -2\n",
    "    phi = 0\n",
    "    \n",
    "    y1 = spinweightedsphericalharmonics(theta, phi, l, m, s)\n",
    "    y2 = (-1)**(-1 * s + m) * np.conj(spinweightedsphericalharmonics(theta, phi, l, m, s))\n",
    "    \n",
    "    Ylm = y1 + (-1)**l * y2\n",
    "    \n",
    "    return Ylm\n",
    "\n",
    "def spinweightedsphericalharmonics(theta, phi, l, m, s):\n",
    "    n = -1 * s\n",
    "    d = small_dmatrix(theta, l, m, n)\n",
    "    \n",
    "    sYlm = (-1)**s * np.sqrt((2*l + 1) / 4 * math.pi) * d * np.exp(1j * m * phi)\n",
    "    \n",
    "    return sYlm\n",
    "\n",
    "def small_dmatrix(theta, l, m, n):\n",
    "    maxk = min(l - m, l - n) + 1\n",
    "    SUM = 0\n",
    "    \n",
    "    for k in range(maxk):\n",
    "        \n",
    "        SUM += (-1)**k * (np.sin(theta / 2))**(2*l - m - n - 2*k) * (np.cos(theta / 2))**(m + n + 2*k) / (math.factorial(k) * math.factorial(l - m - k) * math.factorial(l - n - k) * math.factorial(m + n + k))\n",
    "        \n",
    "    d = (-1)**(l - n) * np.sqrt(math.factorial(l + m) * math.factorial(l - m) * math.factorial(l + n) * math.factorial(l - n)) * SUM\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ringdown_signal_generator : Main function.  \n",
    "QNM_parameter : Calculate QNM parameters(frequency and Q-factor).  \n",
    "plus_GW_spherical_harmonics : Calculate spherical harmonics of GW.  \n",
    "spinweightedsphericalharmonics : Calculate spin-weighted-spherical-harmonics.  \n",
    "small_dmatrix : Calculate Wigner's small-D-matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to set 6 parameters(each mass of two BHs, spin, amplitude, inclination, arrival time of GW) in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# GW parameter\n",
    "m1 = 29\n",
    "m2 = 36\n",
    "a = 0.68\n",
    "theta = 3 * math.pi /2\n",
    "A22 = 6.0 * 10**(-23)\n",
    "tau_index = 2048    # Index of arrival time\n",
    "\n",
    "fs = 4096\n",
    "L = 4096\n",
    "dt = 1.0 / L\n",
    "\n",
    "t = np.linspace(0, 1.0 - dt, L)\n",
    "\n",
    "# Signal\n",
    "signal = Ringdown_signal_generator(m1, m2, a, t, A22, theta, tau_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can get ringdown signal(t-domain), and the size is (4096, )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matched Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can calculate matched-filter $m$ by running 'matched_filter.py'.  \n",
    "The source code is like below.  \n",
    "※ This code is simpler version($\\nu$ is a scalar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matched_filter(noise, signal, fs, massvector, kerrvector, tauvector, nu, thetavector):\n",
    "    \n",
    "    # Preparation\n",
    "    dt = 1.0 / fs\n",
    "    L = len(noise)\n",
    "    t = np.linspace(0, 1, fs)\n",
    "    NFFT = fs         # Length of fourier transoformation\n",
    "    \n",
    "    # PSD estimation\n",
    "    psd, freqs = mlab.psd(noise, Fs=fs, NFFT=NFFT)\n",
    "    df = 1.0           # bin\n",
    "    Lf = len(freqs)\n",
    "    \n",
    "    # Signal + Noise\n",
    "    s = noise + signal\n",
    "    w = sp.signal.hann(L)           # Window function(hunn)\n",
    "    w = w / np.mean(w)\n",
    "    s_fft = np.fft.rfft(s * w)/L\n",
    "    \n",
    "    ## Matched Filter\n",
    "    massvector = np.round(massvector, 3)\n",
    "    kerrvector = np.round(kerrvector, 3)\n",
    "    tauvector = np.round(tauvector, 3)\n",
    "    \n",
    "    ml = len(massvector)\n",
    "    kl = len(kerrvector)\n",
    "    tl = len(tauvector)\n",
    "    thl = len(thetavector)\n",
    "    \n",
    "    # Templates\n",
    "    templates = np.zeros((L, ml, kl, thl))\n",
    "\n",
    "    for i in range(ml):\n",
    "        for j in range(kl):\n",
    "            for k in range(thl):                   \n",
    "                #--------QNM parameter--------#\n",
    "                f, q = QNM_parameter(kerrvector[j], massvector[i])\n",
    "\n",
    "                f_22, f_33, f_44 = f[0], f[1], f[2]\n",
    "                q_22, q_33, q_44 = q[0], q[1], q[2]\n",
    "                    \n",
    "                #--------Amplitude of spherical harmonics--------#\n",
    "                Y22 = plus_GW_spherical_harmonics(thetavector[k], 2, 2)\n",
    "                Y33 = plus_GW_spherical_harmonics(thetavector[k], 3, 3) / Y22\n",
    "                Y44 = plus_GW_spherical_harmonics(thetavector[k], 4, 4) / Y22\n",
    "\n",
    "                #--------Amplitude--------#\n",
    "                A22 = 1.0\n",
    "                A33 = Y33 * A22 * 0.44 * (1- 4*nu)**0.45\n",
    "                A44 = Y44 * A22 *(5.4 * (nu - 0.22)**2 + 0.04)\n",
    "                    \n",
    "                #--------Templates-------#\n",
    "\n",
    "                temp_22 = A22 * np.exp(-math.pi * f_22 / q_22 * t) * np.sin(2 * math.pi * f_22 * t)\n",
    "                temp_33 = A33 * np.exp(-math.pi * f_33 / q_33 * t) * np.sin(2 * math.pi * f_33 * t)\n",
    "                temp_44 = A44 * np.exp(-math.pi * f_44 / q_44 * t) * np.sin(2 * math.pi * f_44 * t)\n",
    "                    \n",
    "                templates[:, i, j, k] = temp_22 + temp_33 + temp_44\n",
    "                \n",
    "                \n",
    "    # Matched Filter\n",
    "    #--------Normalization-------#\n",
    "    temp_fft = np.zeros((int(NFFT/2.0+1), ml, kl, thl))\n",
    "    sigma_sqr = np.zeros((ml, kl, thl))\n",
    "    templates_cal = np.zeros((L, ml, kl, thl))\n",
    "    temp_fft_cal = np.zeros((int(NFFT/2.0+1), ml, kl, thl))\n",
    "    sigma_sqr_cal = np.zeros((ml, kl, thl))\n",
    "\n",
    "    w = sp.signal.hann(NFFT)\n",
    "    w = w / np.mean(w)\n",
    "    \n",
    "    for i in range(ml):\n",
    "        for j in range(kl):\n",
    "            for k in range(thl):\n",
    "                temp_fft[:, i, j, k] = np.fft.rfft(templates[:, i, j, k] * w) / NFFT\n",
    "                sigma_sqr[i, j, k] = 4 * np.real(np.sum((temp_fft[1:, i, j, k] * np.conj(temp_fft[1:, i, j, k]) / psd[1:]) * df))\n",
    "                templates_cal[:, i, j, k] = templates[:, i, j, k] / np.sqrt(sigma_sqr[i, j, k])\n",
    "                temp_fft_cal[:, i, j, k] = np.fft.rfft(templates_cal[:, i, j, k] * w) / NFFT\n",
    "                sigma_sqr_cal[i,j,k] = 4 * np.real(np.sum((temp_fft_cal[1:, i, j, k] * np.conj(temp_fft_cal[1:, i, j, k]) / psd[1:]) * df))\n",
    "    \n",
    "    matchedfilter_cal = np.zeros((ml, kl, tl, thl))\n",
    "                \n",
    "    for i in range(ml):\n",
    "        for j in range(kl):\n",
    "            for k in range(tl):\n",
    "                for l in range(thl):\n",
    "                    matchedfilter_cal[i, j, k, l] = 4 * np.real(np.sum((s_fft[1:] * np.conj(temp_fft_cal[1:, i, j, l]) * np.exp(2 * math.pi *1j * freqs[1:] * tauvector[k]) / psd[1:]) * df))\n",
    "                    \n",
    "    return np.abs(matchedfilter_cal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to set 4 search parameters here(In fact, 5 parameters including $\\nu$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search parameters\n",
    "massvector = np.linspace(10,100,10)\n",
    "kerrvector = np.linspace(0.48,0.88,5)\n",
    "tauvector = np.linspace(0.3,0.7,5)\n",
    "thetavector = np.array([0, math.pi/4, math.pi/2, math.pi*5/4, math.pi*3/2])\n",
    "\n",
    "q = m2/m1\n",
    "nu = q/((1+q)**2)    # Mass ratio is fixed here.\n",
    "\n",
    "# Matched Filtering\n",
    "SNR = matched_filter(noise, signal, fs, massvector, kerrvector, tauvector, nu, thetavector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can get matched-filter $m$, so you go on to statistical testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of statistical testing(DetRate vs FAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmax = 10000    # number of loop\n",
    "\n",
    "# Preparation\n",
    "SNR_storage = np.zeros(kmax)\n",
    "SNR_storage_nosignal = np.zeros(kmax)\n",
    "\n",
    "#--------Preparation for noise--------#\n",
    "data_name = 'GW150914_4096Hz_1s.txt'\n",
    "\n",
    "# Parameters\n",
    "L = 4096\n",
    "fs = 4096\n",
    "dt = 1.0 / fs\n",
    "\n",
    "t = np.linspace(0, 1 - dt, L)\n",
    "\n",
    "strain = data_format(data_name)\n",
    "\n",
    "\n",
    "#--------Preparation for ringdown signal--------#\n",
    "# Parameters\n",
    "a = 0.68       # Spin\n",
    "theta = 3 * math.pi / 2      # Inclination\n",
    "A22 = 1.000000000000001e-22      # Amplitude of fundamental mode\n",
    "tau_index = 2048\n",
    "\n",
    "m1 = 29\n",
    "m2 = 36\n",
    "\n",
    "# Ringdown signal\n",
    "signal = Ringdown_signal_generator(m1, m2, a, t, A22, theta, tau_index)\n",
    "\n",
    "#--------Matched Filtering--------#\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Search parameters\n",
    "massvector = np.linspace(10,100,10)\n",
    "kerrvector = np.linspace(0.48,0.88,5)\n",
    "tauvector = np.linspace(0.3,0.7,5)\n",
    "thetavector = np.array([0, math.pi/4, math.pi/2, math.pi*5/4, math.pi*3/2])\n",
    "\n",
    "q = m2/m1\n",
    "nu = q/((1+q)**2)    # Mass ratio is fixed here\n",
    "\n",
    "\n",
    "for i in range(kmax):\n",
    "    noise = rand_sample(strain, fs, L)\n",
    "    \n",
    "    # Including ringdown signal\n",
    "    SNR = matched_filter(noise, signal, fs, massvector, kerrvector, tauvector, nu, thetavector)\n",
    "    \n",
    "    # Not including ringdown signal\n",
    "    no_signal = np.zeros(4096)\n",
    "    SNR_nosignal = matched_filter(noise, no_signal, fs, massvector, kerrvector, tauvector, nu, thetavector)\n",
    "    \n",
    "    # Max SNR\n",
    "    SNR_storage[i] = np.amax(SNR)\n",
    "    SNR_storage_nosignal[i] = np.amax(SNR_nosignal)\n",
    "    \n",
    "#--------Plotting-------#\n",
    "# Setting of bias\n",
    "ref_min = np.amin(SNR_storage_nosignal)\n",
    "ref_max = np.amax(SNR_storage)\n",
    "ref_val = np.linspace(ref_min, ref_max, 10000)\n",
    "\n",
    "# Preparation for testing\n",
    "num = np.zeros((len(ref_val), 2))\n",
    "\n",
    "# Testing\n",
    "for i in range(len(ref_val)):\n",
    "    num[i,0] = np.sum(ref_val[i] < SNR_storage)\n",
    "    num[i,1] = np.sum(ref_val[i] < SNR_storage_nosignal)\n",
    "    \n",
    "# Number to Probability\n",
    "num = num / kmax\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "plt.scatter(num[:,1], num[:,0], marker='.', s=20)\n",
    "plt.title('DetRate vs FAR')\n",
    "plt.xlabel('False Alarm Rate')\n",
    "plt.ylabel('Detection Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can get results of Matched Filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make train/test dataset by running 'make_train_test.py'.  \n",
    "The source code is like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/GW150914_4096Hz_1s.txt'\n",
    "\n",
    "# Preparation\n",
    "\n",
    "L = 4096\n",
    "fs = 4096\n",
    "dt = 1.0 / fs\n",
    "\n",
    "t = np.linspace(0, 1 - dt, L)\n",
    "\n",
    "# Strain formating\n",
    "\n",
    "strain = data_format(data_path)\n",
    "\n",
    "\n",
    "# GW parameters\n",
    "\n",
    "a = 0.68       # Spin\n",
    "theta = 3 * math.pi / 2      # Inclination\n",
    "A22 = 6.000000000000001e-23      # Amplitude of the fundamental(22) mode\n",
    "\n",
    "train_m1 = np.linspace(5, 100, 20)\n",
    "train_m2 = train_m1\n",
    "test_m1 = np.linspace(7.5, 97.5, 19)\n",
    "test_m2 = test_m1\n",
    "\n",
    "tau_index = np.array([1229, 1639, 2048, 2458, 2867])     # Index of arrival time\n",
    "\n",
    "# Preparation for datasets\n",
    "\n",
    "train_data = np.zeros((2100, 4101))\n",
    "test_data = np.zeros((1900, 4101))\n",
    "\n",
    "# Train Data\n",
    "\n",
    "loop_train = 0\n",
    "\n",
    "for i1 in range(len(train_m1)):\n",
    "    for i2 in range(len(train_m2)):\n",
    "        for i3 in range(len(tau_index)):\n",
    "            if train_m1[i1] <= train_m2[i2]:\n",
    "                ringdown = Ringdown_signal_generator(train_m1[i1], train_m2[i2], a, t, A22, theta, tau_index[i3])\n",
    "                strain = rand_sample(strain, fs, L)\n",
    "                signal = ringdown + strain\n",
    "\n",
    "                # Including ringdown\n",
    "                \n",
    "                train_data[loop_train, 0:L] = signal\n",
    "                train_data[loop_train, L] = train_m1[i1]\n",
    "                train_data[loop_train, L+1] = train_m2[i2]\n",
    "                train_data[loop_train, L+2] = tau_index[i3]\n",
    "                train_data[loop_train, L+3] = 1\n",
    "                train_data[loop_train, L+4] = 0\n",
    "\n",
    "                loop_train += 1\n",
    "\n",
    "                # Not including ringdown\n",
    "\n",
    "                train_data[loop_train, 0:L] = strain\n",
    "                train_data[loop_train, L] = train_m1[i1]\n",
    "                train_data[loop_train, L+1] = train_m2[i2]\n",
    "                train_data[loop_train, L+2] = tau_index[i3]\n",
    "                train_data[loop_train, L+3] = 0\n",
    "                train_data[loop_train, L+4] = 1\n",
    "\n",
    "                loop_train += 1\n",
    "\n",
    "                print('i1:' + str(i1) + ', i2:' + str(i2) + ', i3:' + str(i3) + ', Train:' + str(loop_train / 46560 * 100) + '%')\n",
    "\n",
    "# Test Data\n",
    "\n",
    "loop_test = 0\n",
    "\n",
    "for i1 in range(len(test_m1)):\n",
    "    for i2 in range(len(test_m2)):\n",
    "        for i3 in range(len(tau_index)):\n",
    "            if test_m1[i1] <= test_m2[i2]:\n",
    "                ringdown = Ringdown_signal_generator(test_m1[i1], test_m2[i2], a, t, A22, theta, tau_index[i3])\n",
    "                strain = rand_sample(strain, fs, L)\n",
    "                signal = ringdown + strain\n",
    "\n",
    "                # Including ringdown\n",
    "                \n",
    "                test_data[loop_test, 0:L] = signal\n",
    "                test_data[loop_test, L] = test_m1[i1]\n",
    "                test_data[loop_test, L+1] = test_m2[i2]\n",
    "                test_data[loop_test, L+2] = tau_index[i3]\n",
    "                test_data[loop_test, L+3] = 1\n",
    "                test_data[loop_test, L+4] = 0\n",
    "\n",
    "                loop_test += 1\n",
    "\n",
    "                # Not including ringdown\n",
    "\n",
    "                test_data[loop_test, 0:L] = strain\n",
    "                test_data[loop_test, L] = test_m1[i1]\n",
    "                test_data[loop_test, L+1] = test_m2[i2]\n",
    "                test_data[loop_test, L+2] = tau_index[i3]\n",
    "                test_data[loop_test, L+3] = 0\n",
    "                test_data[loop_test, L+4] = 1\n",
    "\n",
    "                loop_test += 1\n",
    "\n",
    "                print('i1:' + str(i1) + ', i2:' + str(i2) + ', i3:' + str(i3) + ', Test:' + str(loop_test / 1900 * 100) + '%')\n",
    "\n",
    "                \n",
    "# Saving train/test datasets(Numpy array)\n",
    "\n",
    "np.savetxt('data/train_data.csv', train_data, delimiter=',')\n",
    "np.savetxt('data/test_data.csv', test_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set GW parameters which you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the CNN model I used on my master thesis.  \n",
    "You can change hyperparameters(ksize:kernel size, stride, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Block\n",
    "\n",
    "class RingdownBlock(chainer.Chain):\n",
    "    def __init__(self, in_channels, out_channels, ksize, stride):\n",
    "        super(RingdownBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv = L.ConvolutionND(ndim=1, in_channels=in_channels, out_channels=out_channels, ksize=ksize, stride=stride)\n",
    "            self.bn = L.BatchNormalization(out_channels)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.bn(h)\n",
    "        \n",
    "        return h\n",
    "      \n",
    "# CNN modeling\n",
    "\n",
    "class RingdownNet1(chainer.Chain):\n",
    "    def __init__(self, class_labels=2):\n",
    "        super(RingdownNet1, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = RingdownBlock(1, 16, 9, 1)\n",
    "            self.conv2 = RingdownBlock(16, 32, 7, 1)\n",
    "            self.conv3 = RingdownBlock(32, 64, 7, 1)\n",
    "            self.affine1 = L.Linear(None, 32)\n",
    "            self.affine2 = L.Linear(None, class_labels)\n",
    "            #self.bn1 = L.BatchNormalization(32)\n",
    "          \n",
    "            \n",
    "    def __call__(self, x):\n",
    "        # 1st layer(CNN)\n",
    "        h = self.conv1(x)\n",
    "        h = F.max_pooling_nd(h, ksize=4, stride=4)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # 2nd layer(CNN)\n",
    "        h = self.conv2(h)\n",
    "        h = F.max_pooling_nd(h, ksize=4, stride=4)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # 3rd layer(CNN)\n",
    "        h = self.conv3(h)\n",
    "        h = F.max_pooling_nd(h, ksize=4, stride=4)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # 4th layer(fully-connected)\n",
    "        h = self.affine1(h)\n",
    "        #h = self.bn1(h)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # Output layer\n",
    "        h = self.affine2(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training(on Google Colaboratory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process described below is executed on Google Colaboratory.  \n",
    "At first, I define a function about 'random seed'.  \n",
    "This function helps you manage 'random seed' in order not to change on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)    # For numpy\n",
    "    cp.random.seed(seed)    # For cupy\n",
    "    \n",
    "reset_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and Setup of Chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://colab.chainer.org/install | sh -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use chainer on Google Colaboratory.  \n",
    "So, check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True\n",
    "GPU_ID = 0\n",
    "\n",
    "print('cuda.available:', chainer.cuda.available)\n",
    "print('cuda.cudnn_enabled:',chainer.cuda.cudnn_enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading train/test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, you have to mount specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mounting specified directory on Google Drive\n",
    "\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, URL for activation will be displayed twice.  \n",
    "You have to click the URL, login Google and copy activation key.  \n",
    "Finally, fill the activation key in the window on Google Colaboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive mean root directory of  google drive\n",
    "\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "!ls drive/NAME_OF_DIRECTORY/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you've completed activation.  \n",
    "So, go on to the next step(Loading datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test datasets\n",
    "\n",
    "PATH_TRAIN = 'drive/DeepGW/train_data.csv'\n",
    "PATH_TEST = 'drive/DeepGW/test_data.csv'\n",
    "\n",
    "train = np.loadtxt(PATH_TRAIN, delimiter=',')\n",
    "test = np.loadtxt(PATH_TEST, delimiter=',')\n",
    "\n",
    "# Reshape\n",
    "\n",
    "x_train, _, t_train, _ = np.split(train, [4096, 4099, 4100], axis=1)\n",
    "x_train = x_train.reshape(len(x_train), 1, 4096)\n",
    "x_test, _, t_test, _ = np.split(test, [4096, 4099, 4100], axis=1)\n",
    "x_test = x_test.reshape(len(x_test), 1, 4096)\n",
    "\n",
    "\n",
    "# Reshape for mini batch\n",
    "\n",
    "t_train = t_train.reshape(len(t_train))\n",
    "t_test = t_test.reshape(len(t_test))\n",
    "\n",
    "# Numpy -> Cupy\n",
    "\n",
    "x_train, t_train, x_test, t_test = cp.asarray(x_train), cp.asarray(t_train), cp.asarray(x_test), cp.asarray(t_test)\n",
    "\n",
    "# Mini batch\n",
    "\n",
    "train_data = TupleDataset(x_train, t_train)    # Datasets -> Tuple\n",
    "test_data = TupleDataset(x_test, t_test)\n",
    "\n",
    "MINIBATCH_SIZE = 128\n",
    "train_iter = chainer.iterators.SerialIterator(train_data, MINIBATCH_SIZE)    # Iterator\n",
    "test_iter = chainer.iterators.SerialIterator(test_data, MINIBATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you've gotten train/test datasets for cupy/cuda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance\n",
    "reset_seed(0)\n",
    "model = RingdownNet1()\n",
    "\n",
    "if GPU:\n",
    "  chainer.cuda.get_device(GPU_ID).use()\n",
    "  model.to_gpu(GPU_ID)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change a kind of optimizers and hyper parameters(learning rate and so on...).  \n",
    "Now, we are ready to train the model.  \n",
    "Run next code or 'Trainer' , and training is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train and Test\n",
    "\n",
    "from chainer.cuda import to_cpu\n",
    "\n",
    "EPOCH = 10    # Setting training epoch\n",
    "\n",
    "train_loss_list = cp.zeros(EPOCH)\n",
    "train_accuracy_list = cp.zeros(EPOCH)\n",
    "\n",
    "while train_iter.epoch < EPOCH:\n",
    "    batch = train_iter.next()\n",
    "    x_array, t_array = convert.concat_examples(batch, GPU_ID)\n",
    "    x = chainer.Variable(x_array.astype(cp.float32))\n",
    "    t = chainer.Variable(t_array.astype(cp.int32))\n",
    "\n",
    "    y = model(x)\n",
    "    loss_train = F.softmax_cross_entropy(y, t)\n",
    "    model.cleargrads()\n",
    "    loss_train.backward()\n",
    "    optimizer.update()\n",
    "    \n",
    "    # Tesiting generalization ability by epoch\n",
    "    if train_iter.is_new_epoch:  # When 1 epoch is finished\n",
    "\n",
    "        # Loss\n",
    "        print('epoch:{:02d} train_loss:{:.06f} '.format(\n",
    "            train_iter.epoch, float(to_cpu(loss_train.data))), end='')\n",
    "        train_loss_list[train_iter.epoch-1] = loss_train.data\n",
    "\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        while True:\n",
    "            test_batch = test_iter.next()\n",
    "            x_test_array, t_test_array = convert.concat_examples(test_batch, GPU_ID)\n",
    "            x_test = chainer.Variable(x_test_array.astype(cp.float32))\n",
    "            t_test = chainer.Variable(t_test_array.astype(cp.int32))\n",
    "\n",
    "            # Forward test datasets\n",
    "            y_test = model(x_test)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss_test = F.softmax_cross_entropy(y_test, t_test)\n",
    "            test_losses.append(to_cpu(loss_test.array))\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = F.accuracy(y_test, t_test)\n",
    "            accuracy.to_cpu()\n",
    "            test_accuracies.append(accuracy.array)\n",
    "\n",
    "            if test_iter.is_new_epoch:\n",
    "                test_iter.reset()\n",
    "                break\n",
    "\n",
    "        print('test_loss:{:.04f} test_accuracy:{:.06f}'.format(\n",
    "            np.mean(test_losses), np.mean(test_accuracies)))\n",
    "\n",
    "    \n",
    "print('Training is finished')\n",
    "\n",
    "# Visualization of  training process\n",
    "epo = np.linspace(1, EPOCH, EPOCH)\n",
    "plt.plot(epo, cp.asnumpy(train_loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to save parameters(weight and bias), run next code.  \n",
    "Then, you've gotten '.npz' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving parameters\n",
    "\n",
    "model.to_cpu()\n",
    "SAVE_MODEL = '/content/drive/NAME_OF_DIRECTORY/NPZ_FILE_NAME.npz'\n",
    "serializers.save_npz(SAVE_MODEL, model)\n",
    "print('Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading savd parameters\n",
    "\n",
    "SAVE_MODEL = '/content/drive/NAME_OF_DIRECTORY/NPZ_FILE_NAME.npz'\n",
    "model = RingdownNet1()\n",
    "serializers.load_npz(SAVE_MODEL, model, strict=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
